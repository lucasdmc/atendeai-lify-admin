
import { ConversationMemoryManager } from './conversation-memory.ts';
import { HumanizedResponseGenerator } from './humanized-response-generator.ts';
import { LiaPersonality } from './lia-personality.ts';
import { MCPToolsProcessor } from './mcp-tools.ts';
import { TimeContextManager } from './time-context-manager.ts';

export async function generateEnhancedAIResponse(
  contextData: any[],
  recentMessages: any[],
  message: string,
  phoneNumber: string,
  userIntent?: any
): Promise<string> {
  try {
    console.log('ğŸ¤– === SISTEMA DE IA DA LIA INICIADO ===');
    
    // Usar o sistema humanizado da Lia como principal
    console.log('ğŸ§  Gerando prompt da Lia...');
    
    try {
      const liaResponse = await HumanizedResponseGenerator.generateHumanizedResponse(
        message,
        phoneNumber,
        null, // supabase serÃ¡ criado internamente
        contextData,
        recentMessages
      );
      
      // Se recebemos um prompt contextual, processar com OpenAI
      if (liaResponse && liaResponse.includes('CONTEXTO PESSOAL DO PACIENTE')) {
        console.log('ğŸ“ Prompt da Lia gerado com sucesso');
        
        // Processar com MCP Tools
        console.log('ğŸ”§ === PROCESSAMENTO MCP INICIADO ===');
        const mcpResult = await MCPToolsProcessor.processUserMessage(message, contextData);
        console.log('ğŸ”§ MCP processamento concluÃ­do. Resposta:', mcpResult.shouldRespond ? 'Sim' : 'NÃ£o');
        
        // Aplicar contexto temporal
        const timeContext = TimeContextManager.getCurrentTimeContext();
        console.log('âœ… Contexto temporal aplicado');
        
        // Integrar informaÃ§Ãµes do MCP ao prompt
        let enhancedPrompt = liaResponse;
        if (mcpResult.toolsData && Object.keys(mcpResult.toolsData).length > 0) {
          enhancedPrompt += `\n\nINFORMAÃ‡Ã•ES ADICIONAIS DO SISTEMA:\n${JSON.stringify(mcpResult.toolsData, null, 2)}`;
        }
        console.log('ğŸ”§ InformaÃ§Ãµes MCP integradas ao prompt da Lia');
        
        // Processar com OpenAI
        const openaiResponse = await processWithOpenAI(enhancedPrompt, message);
        
        if (openaiResponse) {
          // Aplicar filtros da personalidade da Lia
          const finalResponse = applyLiaPersonalityFilters(openaiResponse, message);
          console.log('âœ… Resposta processada e filtros da Lia aplicados');
          return finalResponse;
        }
      }
      
      // Se Ã© uma saudaÃ§Ã£o direta da Lia (primeiro contato)
      if (liaResponse && !liaResponse.includes('CONTEXTO PESSOAL DO PACIENTE')) {
        console.log('âœ… SaudaÃ§Ã£o da Lia retornada diretamente');
        return liaResponse;
      }
      
    } catch (liaError) {
      console.error('âŒ Erro crÃ­tico no sistema da Lia:', liaError);
    }
    
    // Fallback para resposta da Lia
    console.log('ğŸ”„ Usando fallback da Lia');
    return generateLiaFallbackResponse(message, contextData);
    
  } catch (error) {
    console.error('âŒ Erro crÃ­tico no processamento humanizado:', error);
    return generateLiaFallbackResponse(message, contextData);
  }
}

async function processWithOpenAI(prompt: string, userMessage: string): Promise<string | null> {
  try {
    console.log('ğŸ“¤ Enviando requisiÃ§Ã£o para OpenAI GPT-4o-mini (Lia)...');
    
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiApiKey) {
      console.error('âŒ OPENAI_API_KEY nÃ£o configurada');
      return null;
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'user', content: `${prompt}\n\nMensagem do paciente: "${userMessage}"` }
        ],
        max_tokens: 300,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      console.error('âŒ Erro na resposta da OpenAI:', response.status, response.statusText);
      return null;
    }

    const data = await response.json();
    const aiResponse = data.choices?.[0]?.message?.content;
    
    if (aiResponse) {
      console.log('âœ… Resposta da OpenAI recebida com sucesso');
      return aiResponse.trim();
    }
    
    return null;
  } catch (error) {
    console.error('âŒ Erro ao chamar OpenAI:', error);
    return null;
  }
}

function applyLiaPersonalityFilters(response: string, userMessage: string): string {
  // Aplicar filtros da Lia para garantir personalidade consistente
  let filteredResponse = response;
  
  // Remover linguagem muito tÃ©cnica ou formal
  filteredResponse = filteredResponse.replace(/Prezado\(a\) usuÃ¡rio\(a\)/gi, 'Oi!');
  filteredResponse = filteredResponse.replace(/Como posso auxiliÃ¡-lo\(a\)/gi, 'Como posso te ajudar');
  filteredResponse = filteredResponse.replace(/Ã€ disposiÃ§Ã£o/gi, 'Estou aqui para te ajudar');
  filteredResponse = filteredResponse.replace(/Atenciosamente/gi, '');
  
  // Garantir que nÃ£o mencione ser IA
  filteredResponse = filteredResponse.replace(/Como uma IA/gi, 'Como assistente');
  filteredResponse = filteredResponse.replace(/sou uma inteligÃªncia artificial/gi, 'sou a assistente da clÃ­nica');
  filteredResponse = filteredResponse.replace(/sistema de IA/gi, 'sistema da clÃ­nica');
  
  // Adicionar toque pessoal se nÃ£o tiver emoji
  if (!filteredResponse.includes('ğŸ˜Š') && !filteredResponse.includes('ğŸ’™') && Math.random() > 0.6) {
    const emojis = ['ğŸ˜Š', 'ğŸ’™', 'ğŸ™'];
    const randomEmoji = emojis[Math.floor(Math.random() * emojis.length)];
    filteredResponse += ` ${randomEmoji}`;
  }
  
  // Garantir que termina de forma acolhedora
  if (!filteredResponse.includes('qualquer coisa') && !filteredResponse.includes('mais alguma coisa')) {
    if (Math.random() > 0.7) {
      filteredResponse += '\n\nSe precisar de mais alguma coisa, Ã© sÃ³ me chamar!';
    }
  }
  
  return filteredResponse;
}

function generateLiaFallbackResponse(userMessage: string, contextData: any[]): string {
  console.log('ğŸ”„ Usando resposta de fallback da Lia');
  
  const lowerMessage = userMessage.toLowerCase();
  
  // Respostas da Lia baseadas na mensagem
  if (lowerMessage.includes('ola') || lowerMessage.includes('oi') || lowerMessage.includes('olÃ¡')) {
    return LiaPersonality.getGreetingMessage();
  }
  
  if (lowerMessage.includes('agend')) {
    return `Claro! Vou te ajudar com o agendamento ğŸ˜Š\nPara qual especialidade vocÃª gostaria de agendar?\nE qual data seria melhor para vocÃª? ğŸ’™`;
  }
  
  if (lowerMessage.includes('horario') || lowerMessage.includes('horÃ¡rio')) {
    return `Nossos horÃ¡rios sÃ£o de segunda a sexta, das 8h Ã s 18h ğŸ˜Š\nQual dia seria melhor para vocÃª?\nVou verificar nossa disponibilidade! ğŸ’™`;
  }
  
  if (lowerMessage.includes('doutor') || lowerMessage.includes('medico') || lowerMessage.includes('mÃ©dico')) {
    return `Temos profissionais excelentes! ğŸ˜Š\nPara qual especialidade vocÃª precisa?\nVou verificar qual mÃ©dico estÃ¡ disponÃ­vel para vocÃª ğŸ’™`;
  }

  if (lowerMessage.includes('obrigad') || lowerMessage.includes('valeu')) {
    return `Fico muito feliz em ajudar! ğŸ˜Š\nSe precisar de mais alguma coisa, Ã© sÃ³ me chamar.\nEstou sempre aqui para vocÃª! ğŸ’™`;
  }
  
  // Resposta padrÃ£o da Lia
  return `Entendi! ğŸ˜Š\nMe conta um pouquinho mais sobre o que vocÃª precisa?\nAssim posso te ajudar da melhor forma possÃ­vel ğŸ’™`;
}
