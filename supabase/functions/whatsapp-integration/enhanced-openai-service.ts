
import { HumanizedResponseGenerator } from './humanized-response-generator.ts';
import { MCPTools } from './mcp-tools.ts';
import { LiaPersonality } from './lia-personality.ts';

interface OpenAIMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export async function generateEnhancedAIResponse(
  contextData: any[],
  conversationHistory: any[],
  userMessage: string,
  phoneNumber: string,
  userIntent: any
): Promise<string> {
  console.log('ğŸ¤– === SISTEMA DE IA DA LIA INICIADO ===');
  
  try {
    const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
    if (!OPENAI_API_KEY) {
      console.warn('âš ï¸ OpenAI API key nÃ£o configurada, usando fallback da Lia');
      return this.generateLiaFallbackResponse(userMessage, contextData);
    }

    // Gerar prompt humanizado da Lia
    console.log('ğŸ§  Gerando prompt da Lia...');
    const liaPrompt = await HumanizedResponseGenerator.generateHumanizedResponse(
      userMessage,
      phoneNumber,
      null, // Supabase serÃ¡ mockado internamente se necessÃ¡rio
      contextData,
      conversationHistory
    );

    console.log('ğŸ“ Prompt da Lia gerado com sucesso');

    // Verificar se precisa usar ferramentas MCP
    let mcpResponse = '';
    try {
      mcpResponse = await MCPTools.processWithMCP(userMessage, userIntent, phoneNumber);
    } catch (mcpError) {
      console.warn('âš ï¸ Erro no MCP, continuando sem:', mcpError);
    }
    
    let systemPrompt = liaPrompt;
    if (mcpResponse) {
      systemPrompt += `\n\nINFORMAÃ‡Ã•ES ATUALIZADAS DO SISTEMA:\n${mcpResponse}`;
      console.log('ğŸ”§ InformaÃ§Ãµes MCP integradas ao prompt da Lia');
    }

    // Construir histÃ³rico de mensagens para OpenAI
    const messages: OpenAIMessage[] = [
      {
        role: 'system',
        content: systemPrompt
      }
    ];

    // Adicionar histÃ³rico recente (Ãºltimas 4 mensagens para contexto)
    if (conversationHistory && conversationHistory.length > 0) {
      const recentHistory = conversationHistory.slice(-4);
      recentHistory.forEach((msg) => {
        if (msg.content && msg.content.trim()) {
          messages.push({
            role: msg.message_type === 'received' ? 'user' : 'assistant',
            content: msg.content
          });
        }
      });
    }

    // Adicionar mensagem atual do usuÃ¡rio
    messages.push({
      role: 'user',
      content: userMessage
    });

    console.log('ğŸ“¤ Enviando requisiÃ§Ã£o para OpenAI GPT-4o-mini (Lia)...');

    // Chamar OpenAI API com configuraÃ§Ãµes otimizadas para a personalidade da Lia
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: messages,
        max_tokens: 400, // Reduzido para respostas mais concisas da Lia
        temperature: 0.8, // Mais criativo para personalidade natural
        top_p: 0.9,
        frequency_penalty: 0.4, // Reduz repetiÃ§Ãµes
        presence_penalty: 0.3, // Encoraja variaÃ§Ã£o
        response_format: { type: "text" }
      }),
    });

    if (!response.ok) {
      const errorData = await response.text();
      console.error('âŒ Erro na API OpenAI:', errorData);
      return this.generateLiaFallbackResponse(userMessage, contextData);
    }

    const data = await response.json();
    
    if (!data.choices || data.choices.length === 0) {
      console.error('âŒ Resposta invÃ¡lida da OpenAI');
      return this.generateLiaFallbackResponse(userMessage, contextData);
    }

    let aiResponse = data.choices[0].message.content.trim();
    
    // Aplicar filtros da personalidade da Lia
    aiResponse = this.applyLiaPersonalityFilters(aiResponse);
    
    console.log(`âœ… Resposta da Lia gerada: ${aiResponse.substring(0, 100)}...`);
    console.log(`ğŸ“Š Tokens utilizados: ${data.usage?.total_tokens || 'N/A'}`);

    return aiResponse;

  } catch (error) {
    console.error('âŒ Erro crÃ­tico no sistema da Lia:', error);
    return this.generateLiaFallbackResponse(userMessage, contextData);
  }
}

function applyLiaPersonalityFilters(response: string): string {
  // Filtros para garantir que a resposta estÃ¡ no estilo da Lia
  let filtered = response;
  
  // Remover referÃªncias Ã  IA
  filtered = filtered.replace(/como (?:uma )?(?:IA|inteligÃªncia artificial|assistente virtual)/gi, 'como assistente');
  filtered = filtered.replace(/sou (?:uma )?(?:IA|inteligÃªncia artificial)/gi, 'sou a Lia');
  
  // Garantir tom mais pessoal
  filtered = filtered.replace(/posso auxiliÃ¡-lo/gi, 'posso te ajudar');
  filtered = filtered.replace(/Ã  disposiÃ§Ã£o/gi, 'estou aqui para te ajudar');
  
  // Limitar emojis excessivos
  filtered = filtered.replace(/(ğŸ˜Š|ğŸ’™|ğŸ™){3,}/g, '$1');
  
  return filtered;
}

function generateLiaFallbackResponse(userMessage: string, contextData: any[]): string {
  console.log('ğŸ”„ Gerando resposta de fallback da Lia');
  
  const lowerMessage = userMessage.toLowerCase();
  
  // Respostas contextuais da Lia baseadas na mensagem
  if (lowerMessage.includes('ola') || lowerMessage.includes('oi') || lowerMessage.includes('olÃ¡')) {
    return `Oi! Que bom ter vocÃª aqui! ğŸ˜Š\nSou a Lia, assistente aqui da clÃ­nica.\nCom quem eu tenho o prazer de falar? E como vocÃª estÃ¡ hoje? ğŸ’™\nMe conta como posso te ajudar!`;
  }
  
  if (lowerMessage.includes('agend')) {
    return `Claro! Vou te ajudar com o agendamento ğŸ˜Š\nPara qual especialidade vocÃª gostaria?\nE que dia seria melhor para vocÃª? ğŸ’™`;
  }
  
  if (lowerMessage.includes('horario') || lowerMessage.includes('horÃ¡rio')) {
    return `Nossos horÃ¡rios sÃ£o de segunda a sexta, das 8h Ã s 18h ğŸ˜Š\nQual dia seria melhor para vocÃª?\nVou verificar nossa disponibilidade! ğŸ’™`;
  }
  
  if (lowerMessage.includes('doutor') || lowerMessage.includes('medico') || lowerMessage.includes('mÃ©dico')) {
    return `Temos profissionais excelentes! ğŸ˜Š\nPara qual especialidade vocÃª precisa?\nVou verificar qual mÃ©dico estÃ¡ disponÃ­vel ğŸ’™`;
  }

  if (lowerMessage.includes('obrigad') || lowerMessage.includes('valeu')) {
    return `Fico muito feliz em ajudar! ğŸ˜Š\nSe precisar de mais alguma coisa, Ã© sÃ³ me chamar.\nEstou sempre aqui para vocÃª! ğŸ’™`;
  }
  
  // Resposta padrÃ£o empÃ¡tica da Lia
  return `Entendi! ğŸ˜Š\nMe conta um pouquinho mais sobre o que vocÃª precisa?\nAssim posso te ajudar da melhor forma possÃ­vel ğŸ’™`;
}
