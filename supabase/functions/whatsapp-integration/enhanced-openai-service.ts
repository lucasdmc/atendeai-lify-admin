
import { openAIApiKey } from './config.ts';
import { LiaPersonality } from './lia-personality.ts';
import { MCPToolsProcessor } from './mcp-tools.ts';

// Fun√ß√£o utilit√°ria para verificar se deve responder rapidamente
function shouldRespondQuickly(message: string, recentMessages: any[]): boolean {
  const lowerMessage = message.toLowerCase();
  
  // Respostas r√°pidas para mensagens simples
  const quickResponseTriggers = [
    'oi', 'ol√°', 'hi', 'hello',
    'agend', 'consulta', 'marcar',
    'psicolog', 'cardio', 'dermat',
    'obrigad', 'valeu', 'ok'
  ];
  
  return quickResponseTriggers.some(trigger => lowerMessage.includes(trigger));
}

// Fun√ß√£o utilit√°ria para criar mock do Supabase
function createSupabaseMock() {
  return {
    from: (table: string) => ({
      select: (columns: string) => ({
        gte: (column: string, value: any) => ({
          order: (orderColumn: string, options: any) => ({
            limit: (limitValue: number) => Promise.resolve({ 
              data: [], 
              error: null 
            })
          })
        })
      })
    }),
    functions: {
      invoke: (functionName: string, options: any) => Promise.resolve({ 
        data: { success: true }, 
        error: null 
      })
    }
  };
}

export async function generateEnhancedAIResponse(
  contextData: any[],
  recentMessages: any[],
  message: string,
  phoneNumber: string,
  userIntent?: any
): Promise<string> {
  console.log('ü§ñ === GERA√á√ÉO DE RESPOSTA IA HUMANIZADA (LIA) ===');
  console.log(`üìû N√∫mero: ${phoneNumber}`);
  console.log(`üí¨ Mensagem: ${message}`);
  
  if (!openAIApiKey) {
    console.error('‚ùå OPENAI_API_KEY n√£o configurada');
    return LiaPersonality.getFallbackResponse();
  }

  try {
    // Verificar se √© primeira mensagem
    const isFirstContact = LiaPersonality.isFirstContact(recentMessages);
    console.log(`üëã Primeiro contato: ${isFirstContact ? 'SIM' : 'N√ÉO'}`);

    // Se √© primeiro contato, responder diretamente com sauda√ß√£o
    if (isFirstContact) {
      console.log('üéØ Retornando sauda√ß√£o inicial da Lia...');
      return LiaPersonality.getGreetingMessage();
    }

    // Verificar se √© uma resposta r√°pida e direta (n√£o precisa de desculpas)
    const isQuickResponse = shouldRespondQuickly(message, recentMessages);

    // Para respostas diretas, usar respostas da Lia sem IA
    if (isQuickResponse) {
      console.log('‚ö° Resposta r√°pida da Lia...');
      return LiaPersonality.getFollowUpResponse(message);
    }

    // Gerar prompt contextual da Lia (sem instru√ß√µes de desculpas)
    const liaPrompt = LiaPersonality.generateContextualPrompt(
      message,
      contextData,
      recentMessages,
      isFirstContact
    );

    // Configura√ß√£o da chamada OpenAI com personalidade Lia
    const openAIPayload = {
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: `${liaPrompt}

IMPORTANTE: 
- N√ÉO pe√ßa desculpas desnecessariamente
- Seja natural e direta
- S√≥ se desculpe se realmente houve demora ou problema
- Responda de forma fluida e positiva`
        },
        {
          role: "user", 
          content: message
        }
      ],
      tools: MCPToolsProcessor.getMCPTools(),
      tool_choice: "auto",
      max_tokens: 200,
      temperature: 0.7,
      presence_penalty: 0.3,
      frequency_penalty: 0.2
    };

    console.log('üì§ Enviando para OpenAI com personalidade Lia...');
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openAIApiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(openAIPayload)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`‚ùå Erro OpenAI (${response.status}):`, errorText);
      return LiaPersonality.getFollowUpResponse(message);
    }

    const result = await response.json();
    console.log('üì• Resposta OpenAI recebida');

    if (!result.choices || result.choices.length === 0) {
      console.error('‚ùå Resposta OpenAI vazia');
      return LiaPersonality.getFollowUpResponse(message);
    }

    const choice = result.choices[0];
    let finalResponse = '';

    // Processar tool calls se houver
    if (choice.message?.tool_calls && choice.message.tool_calls.length > 0) {
      console.log('üîß Processando tool calls...');
      const toolCall = choice.message.tool_calls[0];
      
      // Simular supabase para MCP tools
      const mockSupabase = createSupabaseMock();
      
      const toolResult = await MCPToolsProcessor.processToolCall(
        toolCall.function.name,
        JSON.parse(toolCall.function.arguments || '{}'),
        mockSupabase
      );
      
      finalResponse = toolResult;
    } else {
      finalResponse = choice.message?.content || '';
    }

    if (!finalResponse || finalResponse.trim().length === 0) {
      console.log('‚ö†Ô∏è Resposta vazia, usando fallback da Lia');
      return LiaPersonality.getFollowUpResponse(message);
    }

    // Aplicar filtros de personalidade da Lia (sem desculpas desnecess√°rias)
    finalResponse = LiaPersonality.adaptResponseStyle(finalResponse, false, false);
    
    console.log('‚úÖ Resposta final da Lia:', finalResponse);
    return finalResponse;

  } catch (error) {
    console.error('‚ùå Erro cr√≠tico na gera√ß√£o de resposta:', error);
    return LiaPersonality.getFollowUpResponse(message);
  }
}

// Fun√ß√£o para validar resposta da Lia
export function validateLiaResponse(response: string): boolean {
  if (!response || response.trim().length === 0) {
    return false;
  }
  
  // Verificar se n√£o cont√©m termos t√©cnicos ou de IA
  const forbiddenTerms = ['ia', 'artificial', 'bot', 'sistema', 'algoritmo', 'programada'];
  const lowerResponse = response.toLowerCase();
  
  for (const term of forbiddenTerms) {
    if (lowerResponse.includes(term)) {
      console.log(`‚ö†Ô∏è Resposta cont√©m termo proibido: ${term}`);
      return false;
    }
  }
  
  return true;
}
